# ðŸŽ¯ Demo Great Expectations

DemonstraÃ§Ã£o prÃ¡tica de validaÃ§Ã£o de dados usando **Great Expectations** â€” framework open-source para garantir qualidade de dados em pipelines de produÃ§Ã£o.

## ðŸ“‹ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Requisitos](#requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Arquitetura do Great Expectations](#arquitetura-do-great-expectations)
- [Fluxo de ValidaÃ§Ã£o (10 Passos)](#fluxo-de-validaÃ§Ã£o-10-passos)
- [Como Executar](#como-executar)
- [Visualizando os Resultados](#visualizando-os-resultados)
- [IntegraÃ§Ã£o com Orquestradores](#integraÃ§Ã£o-com-orquestradores)
- [PrÃ³ximos Passos](#prÃ³ximos-passos)
- [Suporte e Contato](#suporte-e-contato)

---

## ðŸ“– Sobre o Projeto

Este projeto demonstra como implementar validaÃ§Ã£o de dados robusta e production-ready usando Great Expectations (versÃ£o 1.6.4+). O exemplo valida um dataset CSV simples com regras de qualidade personalizadas, gerando relatÃ³rios HTML interativos automaticamente.

### âœ¨ Funcionalidades

- âœ… ValidaÃ§Ã£o automÃ¡tica de dados com 7 expectations (regras de qualidade)
- âœ… GeraÃ§Ã£o de relatÃ³rios HTML (Data Docs) apÃ³s cada validaÃ§Ã£o
- âœ… ConfiguraÃ§Ã£o persistente (checkpoints, expectations suites)
- âœ… Pronto para integraÃ§Ã£o com orquestradores (Airflow, Prefect)
- âœ… Auditabilidade e rastreamento de execuÃ§Ãµes

---

## ðŸ› ï¸ Requisitos

- **Python**: 3.12
- **Poetry**: Gerenciador de dependÃªncias
- **Great Expectations**: >=1.6.4, <2.0.0

---

## ðŸ“¦ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/demo-great-expectations.git
cd demo-great-expectations

# Instale as dependÃªncias com Poetry
poetry install

# Ative o ambiente virtual
poetry shell
```

---

## ðŸ“ Estrutura do Projeto

```
demo-great-expectations/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv              # Dataset de exemplo (10 registros)
â”œâ”€â”€ gx/                          # ConfiguraÃ§Ãµes do Great Expectations (versionadas)
â”‚   â”œâ”€â”€ great_expectations.yml   # Config principal do contexto
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â””â”€â”€ checkpoint.yml       # Checkpoint persistido
â”‚   â”œâ”€â”€ expectations/
â”‚   â”‚   â””â”€â”€ expectation.json     # Expectation Suite persistida
â”‚   â””â”€â”€ uncommitted/             # Resultados (nÃ£o versionados - .gitignore)
â”‚       â”œâ”€â”€ data_docs/           # Data Docs HTML gerados
â”‚       â””â”€â”€ validations/         # JSONs dos resultados
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_quality.py          # Script principal de validaÃ§Ã£o
â”œâ”€â”€ pyproject.toml               # DependÃªncias do projeto
â””â”€â”€ README.md                    # Esta documentaÃ§Ã£o
```

---

## ðŸ—ï¸ Arquitetura do Great Expectations

O Great Expectations segue uma arquitetura modular e declarativa:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DataContext (contexto)                   â”‚
â”‚  Gerenciador central: configuraÃ§Ãµes, stores, checkpoints    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼             â–¼             â–¼
â”â”â”â”â”â”â”â”â”â”â”“   â”â”â”â”â”â”â”â”â”â”â”“   â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Sources â”ƒ   â”ƒ Suites  â”ƒ   â”ƒCheckpointsâ”ƒ
â”—â”â”â”â”â”â”â”â”â”â”›   â”—â”â”â”â”â”â”â”â”â”â”›   â”—â”â”â”â”â”â”â”â”â”â”›
      â”‚             â”‚             â”‚
      â–¼             â–¼             â–¼
[Datasources] [Expectations] [Validations]
   [Assets]      [Rules]      [Actions]
  [Batches]
```

---

## ðŸ”„ Fluxo de ValidaÃ§Ã£o (10 Passos)

### 1ï¸âƒ£ **Criar um Contexto (DataContext)**

**O que Ã©:** O "gerenciador central" do Great Expectations â€” armazena configuraÃ§Ãµes, datasources, suites, checkpoints, resultados.

**Tipos:**
- `mode="file"` â†’ Persiste tudo em `great_expectations/` (produÃ§Ã£o)
- `mode="ephemeral"` â†’ TemporÃ¡rio, nÃ£o salva arquivos (testes/notebooks)

**CÃ³digo:**
```python
context = gx.get_context(mode="file")
```

---

### 2ï¸âƒ£ **Criar um Datasource**

**O que Ã©:** Representa a **origem dos dados** (Pandas DataFrame, SQL, Spark, S3, etc.)

**Por que precisa:** Define como o GE se conecta aos dados e gera batches.

**CÃ³digo:**
```python
data_source = context.data_sources.add_pandas(name="pandas")
```

---

### 3ï¸âƒ£ **Criar um Data Asset**

**O que Ã©:** Um "ponteiro lÃ³gico" para um conjunto de dados dentro do datasource (ex.: uma tabela, um arquivo CSV, um DataFrame).

**Por que precisa:** Organiza e nomeia os dados que vocÃª quer validar.

**CÃ³digo:**
```python
data_asset = data_source.add_dataframe_asset(name="pd_dataframe_asset")
```

---

### 4ï¸âƒ£ **Criar um Batch Definition**

**O que Ã©:** Define **como** criar um batch (lote) de dados a partir do Data Asset.

**Tipos:**
- `add_batch_definition_whole_dataframe` â†’ Valida o DataFrame inteiro
- `add_batch_definition_daily` â†’ Divide por data (Ãºtil para sÃ©ries temporais)

**Por que precisa:** Permite parametrizar quais dados validar (ex.: passar `batch_parameters={"dataframe": df}` em runtime).

**CÃ³digo:**
```python
batch_definition = data_asset.add_batch_definition_whole_dataframe("batch_definition")
```

---

### 5ï¸âƒ£ **Criar a Expectation Suite (com as expectativas)**

**O que Ã©:** Um conjunto nomeado de **regras de validaÃ§Ã£o** (expectations) que vocÃª quer aplicar aos dados.

**Exemplos de expectations:**
- `ExpectColumnToExist` â†’ Coluna deve existir
- `ExpectColumnValuesToNotBeNull` â†’ Sem valores nulos
- `ExpectColumnValuesToBeBetween` â†’ Valores em um range

**Por que precisa:** Define **o que** vocÃª espera dos dados.

**CÃ³digo:**
```python
suite = context.suites.add(
    gx.core.expectation_suite.ExpectationSuite(name="expectation")
)
suite.add_expectation(
    gx.expectations.ExpectColumnToExist(column="id")
)
```

**Expectations configuradas neste projeto:**
1. âœ… `ExpectColumnToExist` â€” Coluna "id" deve existir
2. âœ… `ExpectTableColumnCountToBeBetween` â€” Entre 1-3 colunas
3. âœ… `ExpectTableRowCountToBeBetween` â€” Entre 1-100 linhas
4. âœ… `ExpectColumnValuesToNotBeNull` â€” Coluna "id" sem valores nulos
5. âœ… `ExpectColumnValuesToBeBetween` â€” Valores "id" entre 1-10
6. âœ… `ExpectColumnValuesToBeUnique` â€” Valores "id" Ãºnicos
7. âœ… `ExpectColumnUniqueValueCountToBeBetween` â€” 1-10 valores Ãºnicos em "id"

---

### 6ï¸âƒ£ **Criar o Validation Definition**

**O que Ã©:** Liga um **Batch Definition** (dados) a uma **Expectation Suite** (regras).

**Por que precisa:** Define **qual batch validar** com **quais expectations**.

**CÃ³digo:**
```python
validation_definition = context.validation_definitions.add(
    gx.core.validation_definition.ValidationDefinition(
        name="validation_definition",
        data=batch_definition,  # â† quais dados
        suite=suite,            # â† quais regras
    )
)
```

âš ï¸ **Nota:** NÃ£o confundir com `Validator` (objeto de runtime usado em notebooks).

---

### 7ï¸âƒ£ **Criar configuraÃ§Ãµes para Data Docs (site HTML)**

**O que Ã©:** Configura onde/como gerar os relatÃ³rios HTML de validaÃ§Ã£o.

**Por que precisa:** Para visualizar resultados em um navegador (auditoria, compartilhamento).

**CÃ³digo:**
```python
site_config = {
    "class_name": "SiteBuilder",
    "site_index_builder": {"class_name": "DefaultSiteIndexBuilder"},
    "store_backend": {
        "class_name": "TupleFilesystemStoreBackend",
        "base_directory": "uncommitted/data_docs/local_site/",
    },
}
context.add_data_docs_site(site_name="my_data_docs_site", site_config=site_config)
```

---

### 8ï¸âƒ£ **Actions (AÃ§Ãµes do Checkpoint)**

**O que sÃ£o:** Tarefas automÃ¡ticas que o Checkpoint executa **depois** de cada validaÃ§Ã£o.

**Exemplos comuns:**
- `StoreValidationResultAction` â†’ Salva o JSON do resultado em `great_expectations/uncommitted/validations/`
- `UpdateDataDocsAction` â†’ ReconstrÃ³i os Data Docs HTML com os novos resultados
- `SlackNotificationAction` â†’ Envia notificaÃ§Ã£o Slack em caso de falha/sucesso

**Por que usar:** Automatiza persistÃªncia, geraÃ§Ã£o de relatÃ³rios e integraÃ§Ãµes sem cÃ³digo manual.

**CÃ³digo:**
```python
actions = [
    gx.checkpoint.actions.UpdateDataDocsAction(
        name="update_my_site",
        site_names=["my_data_docs_site"],
    )
]
```

---

### 9ï¸âƒ£ **Checkpoint**

**O que Ã©:** Um "job" configurÃ¡vel que:
1. Executa uma ou mais **Validation Definitions** (valida dados com expectations)
2. Executa **Actions** (salva resultados, gera docs, notifica)

**Por que usar:** Para orquestraÃ§Ã£o e automaÃ§Ã£o â€” Airflow/Prefect/CI chamam checkpoints.

**CÃ³digo:**
```python
checkpoint = context.checkpoints.add(
    gx.checkpoint.checkpoint.Checkpoint(
        name="checkpoint",
        validation_definitions=[validation_definition],  # â† o que validar
        actions=actions,                                # â† o que fazer depois
    )
)
```

---

### ðŸ”Ÿ **Checkpoint Result**

**O que Ã©:** O **resultado** da execuÃ§Ã£o do checkpoint â€” contÃ©m:
- Sucesso/falha geral (`success: true/false`)
- Resultados de cada validaÃ§Ã£o (quais expectations passaram/falharam)
- EstatÃ­sticas (% sucesso, valores observados, etc.)
- Metadados (run_id, timestamp, etc.)

**Por que usar:** Para:
- Verificar programaticamente se a validaÃ§Ã£o passou
- Tomar decisÃµes (ex.: interromper pipeline se `success == False`)
- Debug (ver quais expectations falharam)

**CÃ³digo:**
```python
checkpoint_result = checkpoint.run(
    batch_parameters={"dataframe": df},  # â† passa o DataFrame em runtime
    run_id=RunIdentifier(run_name=f"demo_run_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"),
)

# Verificar sucesso
if checkpoint_result["success"]:
    print("âœ… ValidaÃ§Ã£o passou!")
else:
    print("âŒ ValidaÃ§Ã£o falhou!")
    # Interromper pipeline, enviar alerta, etc.
```

---

## ðŸ“Š Resumo Visual do Fluxo

```
1. Context         â† Gerenciador central (configuraÃ§Ãµes, stores)
   â†“
2. Datasource      â† Como conectar aos dados (Pandas, SQL, etc.)
   â†“
3. Data Asset      â† "Ponteiro" para um conjunto de dados
   â†“
4. Batch Definition â† Como criar um batch (lote) dos dados
   â†“
5. Expectation Suite â† Regras de validaÃ§Ã£o (o que esperar)
   â†“
6. Validation Definition â† Liga batch + suite (o que validar + com quais regras)
   â†“
7. Data Docs Config â† Onde/como gerar relatÃ³rios HTML
   â†“
8. Actions         â† Tarefas automÃ¡ticas pÃ³s-validaÃ§Ã£o (salvar, gerar docs, notificar)
   â†“
9. Checkpoint      â† "Job" que executa validations + actions
   â†“
10. Checkpoint Result â† Resultado da execuÃ§Ã£o (sucesso/falha, estatÃ­sticas)
```

---

## ðŸŽ¯ Analogia PrÃ¡tica (Pipeline de Dados)

Imagine um **sistema de controle de qualidade em uma fÃ¡brica**:

| Componente | Analogia |
|------------|----------|
| **Context** | ConfiguraÃ§Ã£o da fÃ¡brica (onde ficam as mÃ¡quinas, registros) |
| **Datasource** | Esteira transportadora (de onde vÃªm os produtos) |
| **Data Asset** | Tipo de produto (ex.: "lote de parafusos") |
| **Batch Definition** | Tamanho do lote a inspecionar (ex.: "todos os parafusos do dia") |
| **Expectation Suite** | Lista de checagem de qualidade (ex.: "diÃ¢metro 5mm Â± 0.1mm", "sem ferrugem") |
| **Validation Definition** | InstruÃ§Ã£o: "inspecionar lote X com checklist Y" |
| **Data Docs Config** | Onde imprimir o relatÃ³rio de inspeÃ§Ã£o |
| **Actions** | O que fazer apÃ³s inspeÃ§Ã£o (salvar resultado, gerar relatÃ³rio, ligar para supervisor se falhar) |
| **Checkpoint** | O operador que executa a inspeÃ§Ã£o + aÃ§Ãµes automÃ¡ticas |
| **Checkpoint Result** | RelatÃ³rio final ("aprovado"/"reprovado", detalhes) |

---

## ðŸš€ Como Executar

### ExecuÃ§Ã£o Local

```bash
# Ativar ambiente Poetry
poetry shell

# Executar validaÃ§Ã£o
python src/data_quality.py
```

**SaÃ­da esperada:**
```
Calculating Metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 1237.21it/s]
{
    "success": true,
    "statistics": {
        "evaluated_validations": 1,
        "success_percent": 100.0,
        "successful_validations": 1,
        "unsuccessful_validations": 0
    },
    ...
}
```

O navegador abrirÃ¡ automaticamente com os Data Docs.

---

## ðŸ“Š Visualizando os Resultados

### Data Docs (RelatÃ³rios HTML)

ApÃ³s executar o script, o Great Expectations gera automaticamente:

```
gx/uncommitted/data_docs/local_site/
â”œâ”€â”€ index.html                    # â† Home (lista de validaÃ§Ãµes)
â”œâ”€â”€ expectations/
â”‚   â””â”€â”€ expectation.html          # â† DocumentaÃ§Ã£o das regras
â””â”€â”€ validations/
    â””â”€â”€ expectation/
        â””â”€â”€ demo_run_*/
            â””â”€â”€ *.html            # â† Resultados detalhados
```

**Como visualizar:**
1. Abra `gx/uncommitted/data_docs/local_site/index.html` no navegador
2. Navegue para **"Validation Results"** (aba superior)
3. Clique em uma linha para ver detalhes da execuÃ§Ã£o

**InformaÃ§Ãµes disponÃ­veis:**
- âœ… Status geral (sucesso/falha)
- ðŸ“Š EstatÃ­sticas (% sucesso, valores observados)
- ðŸ“‹ Detalhes por expectation (passou/falhou, unexpected_count, etc.)
- ðŸ• Timestamp e Run Name
- ðŸ“ Asset e Batch utilizados

---

## ðŸ”— IntegraÃ§Ã£o com Orquestradores

### Exemplo: Airflow DAG

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import pandas as pd
import great_expectations as gx
from great_expectations.core.run_identifier import RunIdentifier

def validate_data(**context):
    # 1. Carregar dados
    df = pd.read_csv("/path/to/dataset.csv")

    # 2. Carregar contexto GE (do disco)
    ge_context = gx.get_context(context_root_dir="/path/to/great_expectations")

    # 3. Executar checkpoint (configuraÃ§Ã£o persistida)
    checkpoint_result = ge_context.run_checkpoint(
        checkpoint_name="checkpoint",
        batch_parameters={"dataframe": df},
        run_id=RunIdentifier(run_name=f"airflow_{datetime.now().isoformat()}"),
    )

    # 4. Verificar sucesso e interromper pipeline se falhar
    if not checkpoint_result["success"]:
        raise ValueError("Data validation failed!")

    return checkpoint_result["success"]

with DAG(
    dag_id="data_quality_validation",
    start_date=datetime(2025, 1, 1),
    schedule_interval="@daily",
) as dag:

    validate_task = PythonOperator(
        task_id="validate_with_ge",
        python_callable=validate_data,
    )
```

**Vantagens:**
- âœ… ConfiguraÃ§Ãµes versionadas no Git (`gx/checkpoints/`, `gx/expectations/`)
- âœ… ReutilizÃ¡vel em mÃºltiplos DAGs/equipes
- âœ… Auditabilidade e rastreamento completo
- âœ… InterrupÃ§Ã£o automÃ¡tica de pipeline em caso de falha

---

## ðŸš€ PrÃ³ximos Passos

1. **Teste com dados que falham**
   - Altere o CSV para incluir valores nulos/duplicados
   - Observe como o `checkpoint_result` mostra falhas detalhadas

2. **Adicione mais actions**
   ```python
   actions = [
       gx.checkpoint.actions.StoreValidationResultAction(
           name="store_validation_result"
       ),
       gx.checkpoint.actions.UpdateDataDocsAction(
           name="update_my_site",
           site_names=["my_data_docs_site"],
       ),
   ]
   ```

3. **Integre com orquestrador**
   - Crie um DAG do Airflow usando `context.run_checkpoint()`
   - Configure notificaÃ§Ãµes (Slack, email) em caso de falha

4. **Versionamento completo**
   ```bash
   git add gx/checkpoints/ gx/expectations/ gx/great_expectations.yml
   git commit -m "Add GE configuration for production"
   ```

5. **Expanda validaÃ§Ãµes**
   - Adicione expectations para outras colunas
   - Crie mÃºltiplas suites (dev, staging, prod)
   - Valide dados de mÃºltiplas fontes (SQL, S3, APIs)

---

## ðŸ“ž Suporte e Contato

**Jadeson Bruno**
- ðŸ“§ Email: jadesonbruno.a@outlook.com
- ðŸ™ GitHub: [@JadesonBruno](https://github.com/JadesonBruno)
- ðŸ’¼ LinkedIn: [Jadeson Bruno](https://www.linkedin.com/in/jadeson-silva/)

---

â­ **Se este projeto foi Ãºtil, deixe uma estrela no repositÃ³rio!**

ðŸ“ **LicenÃ§a**: MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.
